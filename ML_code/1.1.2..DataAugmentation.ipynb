{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Augmentation\n",
    "\n",
    "This notebook has the purpose of applying some data augmetnation to the current dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read and process the files that contain the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and create the source and destination folders\n",
    "videos_src_folder = '../data/raw/videos'\n",
    "csvs_src_folder = '../data/raw/csvs'\n",
    "dataset_dest_folder = '../data/processed/ImageDatasetRGB_Augmented'\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(os.path.dirname(dataset_dest_folder)):\n",
    "        os.mkdir(dataset_dest_folder)\n",
    "        os.mkdir(os.path.join(dataset_dest_folder, 'features'))\n",
    "        os.mkdir(os.path.join(dataset_dest_folder, 'labels'))    \n",
    "\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "    print('Dataset Destination Folders already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will delete any unrelated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['1.csv', '2.csv', '3.csv', '4.csv', '5.csv', 'Animal61980.csv',\n",
       "        'Animal62418.csv', 'HD_ChR2_480A.csv', 'HD_ChR2_510A.csv',\n",
       "        'HD_ChR2_586A.csv', 'HD_YFP_037A.csv', 'HD_YFP_443A.csv',\n",
       "        'HD_YFP_463A.csv', 'WT_ChR2_087A.csv', 'WT_ChR2_400A.csv',\n",
       "        'WT_ChR2_425A.csv', 'WT_ChR2_635A.csv', 'WT_ChR2_654A.csv',\n",
       "        'WT_YFP_154A.csv', 'WT_YFP_435A.csv', 'WT_YFP_535A.csv',\n",
       "        'WT_YFP_602A.csv', 'WT_YFP_741A.csv', 'WT_YFP_792.csv'],\n",
       "       dtype='<U16'),\n",
       " array(['037A.mp4', '087A.mp4', '1.mp4', '154A.mp4', '2.mp4', '3.mp4',\n",
       "        '4.mp4', '400A.mp4', '425A.mp4', '435A.mp4', '443A.mp4',\n",
       "        '463A.mp4', '480A.mp4', '5.mp4', '510A.mp4', '535A.mp4',\n",
       "        '586A.mp4', '602A.mp4', '635A.mp4', '654A.mp4', '741A.mp4',\n",
       "        '792.mp4', 'Video_Animal61980_10min.mp4',\n",
       "        'Video_Animal62418_10min.mp4'], dtype='<U27'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the content from the source folders\n",
    "csvs = sorted(os.listdir(csvs_src_folder))\n",
    "videos = sorted(os.listdir(videos_src_folder))\n",
    "\n",
    "# Clean unecessary files\n",
    "count_delated = 0\n",
    "for i in range(len(csvs)):\n",
    "    if csvs[i-count_delated][:2] == '._' :\n",
    "        csvs = np.delete(csvs, i-count_delated)\n",
    "        count_delated += 1\n",
    "    elif 'gitkeep' in csvs[i-count_delated]:\n",
    "        csvs = np.delete(csvs, i-count_delated)\n",
    "        count_delated += 1\n",
    "    elif 'DS_Store' in csvs[i-count_delated]:\n",
    "        csvs = np.delete(csvs, i-count_delated)\n",
    "        count_delated += 1\n",
    "\n",
    "count_delated = 0\n",
    "for i in range(len(videos)):\n",
    "    if  videos[i-count_delated][:2] == '._' :\n",
    "        videos = np.delete(videos, i-count_delated)\n",
    "        count_delated += 1\n",
    "    elif 'gitkeep' in videos[i-count_delated]:\n",
    "        videos = np.delete(videos, i-count_delated)\n",
    "        count_delated += 1\n",
    "    elif 'DS_Store' in videos[i-count_delated]:\n",
    "        videos = np.delete(videos, i-count_delated)\n",
    "        count_delated += 1\n",
    "        \n",
    "csvs, videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will sort them with the same order on both lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.mp4', '2.mp4', '3.mp4', '4.mp4', '5.mp4', 'Video_Animal61980_10min.mp4', 'Video_Animal62418_10min.mp4', '480A.mp4', '510A.mp4', '586A.mp4', '037A.mp4', '443A.mp4', '463A.mp4', '087A.mp4', '400A.mp4', '425A.mp4', '635A.mp4', '654A.mp4', '154A.mp4', '435A.mp4', '535A.mp4', '602A.mp4', '741A.mp4', '792.mp4']\n",
      "['1.csv', '2.csv', '3.csv', '4.csv', '5.csv', 'Animal61980.csv', 'Animal62418.csv', 'HD_ChR2_480A.csv', 'HD_ChR2_510A.csv', 'HD_ChR2_586A.csv', 'HD_YFP_037A.csv', 'HD_YFP_443A.csv', 'HD_YFP_463A.csv', 'WT_ChR2_087A.csv', 'WT_ChR2_400A.csv', 'WT_ChR2_425A.csv', 'WT_ChR2_635A.csv', 'WT_ChR2_654A.csv', 'WT_YFP_154A.csv', 'WT_YFP_435A.csv', 'WT_YFP_535A.csv', 'WT_YFP_602A.csv', 'WT_YFP_741A.csv', 'WT_YFP_792.csv']\n"
     ]
    }
   ],
   "source": [
    "csvs = sorted(csvs)\n",
    "videos_aux = []\n",
    "\n",
    "for file in csvs:\n",
    "    if 'Animal' in file:\n",
    "        name = 'Video_' + file.split('.')[0] + '_10min.mp4'\n",
    "    elif len(file.split('.')[0]) > 2:\n",
    "        name = file.split('.')[0].split('_')[-1] + '.mp4'\n",
    "    else: \n",
    "        name = file.split('.')[0] + '.mp4'\n",
    "    videos_aux.append(videos[np.where(np.char.find(videos, name) == 0)][0])\n",
    "\n",
    "videos = videos_aux\n",
    "print(videos)\n",
    "print(sorted(csvs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calsisfy videos regarding their recording conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a method to automatically find the central position of the mouse and crop the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, expansion):\n",
    "    \n",
    "    # Start by converting the image to Gray scale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Rescale the values to highlight constrasted areas\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Crop the box\n",
    "    thresh2 = np.invert(thresh)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    close = cv2.morphologyEx(thresh2, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    \n",
    "    # We want to avoid noise, for that we will just consider the biggest countour since it is going to be the box\n",
    "    c = 0\n",
    "    c_len = len(cnts[0])\n",
    "    for i in range(len(cnts[1:])):\n",
    "        if len(cnts[i]) > c_len:\n",
    "            c = i\n",
    "            c_len = len(cnts[i])          \n",
    "    \n",
    "    # Obtain bounding rectangle to get the box coordinates\n",
    "    x,y,w,h = cv2.boundingRect(cnts[c])\n",
    "\n",
    "    # If the box is way to big, we won't need to crop it, else we will \n",
    "    # If the box isnot detected by the filter, then we can consider it is big enough to not crop it\n",
    "    if not (x+w - x) < image.shape[0]//4:\n",
    "        image = image[y:y+h, x:x+w]\n",
    "        thresh = thresh[y:y+h, x:x+w]\n",
    "\n",
    "    # We can now look for the mouse contour\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "   \n",
    "    # We want to avoid noise, for that we will just consider the biggest countour since it is going to be the mouse, as long as it is not\n",
    "    # to close to the extremes of the image, since that would mean it is an external object\n",
    "    c = 0\n",
    "    c_len = len(cnts[0])\n",
    "    for i in range(len(cnts[1:])):\n",
    "        if len(cnts[i]) > c_len:\n",
    "            # Obtain bounding rectangle to get measurements\n",
    "            x,y,w,h = cv2.boundingRect(cnts[i])\n",
    "            if not (y < 100) or not (y+h > image.shape[0]-100):\n",
    "                c = i\n",
    "                c_len = len(cnts[i])\n",
    "\n",
    "    # Crate a bounding box arround the mouse\n",
    "    x,y,w,h = cv2.boundingRect(cnts[c])\n",
    "    \n",
    "    # Find centroid, this will be the center position of the mouse\n",
    "    M = cv2.moments(cnts[c])            \n",
    "    cX = int(M[\"m10\"] / (M[\"m00\"] + 1e-10))\n",
    "    cY = int(M[\"m01\"] / (M[\"m00\"]+ 1e-10))\n",
    "    midbody = [cX,cY]\n",
    "    top = max(0, midbody[0] - expansion) - max(0, midbody[0] + expansion - image.shape[1])\n",
    "    bottom = min(image.shape[1], midbody[0] + expansion) + max(0, expansion - midbody[0])\n",
    "    left = max(0, midbody[1] - expansion) - max(0, midbody[1] + expansion - image.shape[0])\n",
    "    right = min(image.shape[0], midbody[1] + expansion) + max(0, expansion - midbody[1])\n",
    "   \n",
    "    #Get cropped binary image and clean it with erosion\n",
    "    #final = thresh[left:right,top:bottom]\n",
    "    #kernel = np.ones((3, 3), np.uint8) \n",
    "    #final = cv2.erode(final, kernel, iterations=1) \n",
    "    #return final\n",
    "    \n",
    "    #Return cropped image\n",
    "    return image[left:right,top:bottom]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can start processing the videos. We will generate up to 20 new videos with data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.mp4 2.csv\n",
      "2.csv\n",
      "DF:  (12055, 2)\n",
      "Video FPS:  29.97\n",
      "Label rows:  (4022, 2)\n",
      "Video frames:  4022\n",
      "635A.mp4 WT_ChR2_635A.csv\n",
      "WT_ChR2_635A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "087A.mp4 WT_ChR2_087A.csv\n",
      "WT_ChR2_087A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "037A.mp4 HD_YFP_037A.csv\n",
      "HD_YFP_037A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "480A.mp4 HD_ChR2_480A.csv\n",
      "HD_ChR2_480A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "510A.mp4 HD_ChR2_510A.csv\n",
      "HD_ChR2_510A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "654A.mp4 WT_ChR2_654A.csv\n",
      "WT_ChR2_654A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "443A.mp4 HD_YFP_443A.csv\n",
      "HD_YFP_443A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "154A.mp4 WT_YFP_154A.csv\n",
      "WT_YFP_154A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "1.mp4 1.csv\n",
      "1.csv\n",
      "DF:  (10884, 2)\n",
      "Video FPS:  29.97\n",
      "Label rows:  (3631, 2)\n",
      "Video frames:  3631\n",
      "Video_Animal61980_10min.mp4 Animal61980.csv\n",
      "Animal61980.csv\n",
      "DF:  (6000, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6000, 2)\n",
      "Video frames:  6000\n",
      "586A.mp4 HD_ChR2_586A.csv\n",
      "HD_ChR2_586A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "602A.mp4 WT_YFP_602A.csv\n",
      "WT_YFP_602A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "463A.mp4 HD_YFP_463A.csv\n",
      "HD_YFP_463A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "425A.mp4 WT_ChR2_425A.csv\n",
      "WT_ChR2_425A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video_Animal62418_10min.mp4 Animal62418.csv\n",
      "Animal62418.csv\n",
      "DF:  (6000, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6000, 2)\n",
      "Video frames:  6000\n",
      "741A.mp4 WT_YFP_741A.csv\n",
      "WT_YFP_741A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "4.mp4 4.csv\n",
      "4.csv\n",
      "DF:  (13558, 2)\n",
      "Video FPS:  29.97\n",
      "Label rows:  (4523, 2)\n",
      "Video frames:  4524\n",
      "5.mp4 5.csv\n",
      "5.csv\n",
      "DF:  (12178, 2)\n",
      "Video FPS:  29.97\n",
      "Label rows:  (4063, 2)\n",
      "Video frames:  4063\n",
      "535A.mp4 WT_YFP_535A.csv\n",
      "WT_YFP_535A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n"
     ]
    }
   ],
   "source": [
    "expansion = 80\n",
    "behaviours = ['grooming', 'rearing']\n",
    "fps = 10\n",
    "seen_videos= []\n",
    "\n",
    "for _ in range(20):\n",
    "\n",
    "    # Choose random video and csv\n",
    "    while True:\n",
    "        idx = np.random.randint(0,len(videos))\n",
    "        if idx not in seen_videos:\n",
    "            break\n",
    "            \n",
    "    csv = csvs[idx]\n",
    "    video = videos[idx]\n",
    "    seen_videos.append(idx)\n",
    "\n",
    "    print(video, csv)\n",
    "\n",
    "    # Read columns from csvs corresponding to the behaviours\n",
    "    df = pd.read_csv(os.path.join(csvs_src_folder, csv), header=0)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    \n",
    "    if 'rearing' in df.columns:\n",
    "        df = df[behaviours]\n",
    "    else:\n",
    "        rearing = np.maximum(df['rearing mig'], df['rearing paret'])\n",
    "        df_aux = pd.DataFrame()\n",
    "        df_aux['grooming'] = df['grooming']\n",
    "        df_aux['rearing'] = rearing \n",
    "        df = df_aux\n",
    "        \n",
    "    # Change voids per 0 \n",
    "    df.fillna(0, inplace=True)\n",
    "    # Change data format\n",
    "    df = df.astype(int)\n",
    "    # Reset row indexes\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    # Save df as csv\n",
    "    df.to_csv(os.path.join(dataset_dest_folder, 'labels', csv.split('.')[0] + '_augmented.csv'), index=False)\n",
    "    print(csv)\n",
    "    print('DF: ', df.shape)\n",
    "\n",
    "    # Get video frames\n",
    "    os.mkdir(os.path.join(dataset_dest_folder, 'features',(csv.split('.')[0]+'_augmented')))\n",
    "    vidcap = cv2.VideoCapture(os.path.join(videos_src_folder, video))              \n",
    "\n",
    "    # Get the video FPS rate\n",
    "    fps_in = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    print('Video FPS: ', fps_in)\n",
    "\n",
    "    # Start processing each frame\n",
    "    success,image = vidcap.read()\n",
    "\n",
    "    frames_in = 0\n",
    "    frames_out = 0\n",
    "    count = 0\n",
    "    count_df = 0\n",
    "    drop_indx = []\n",
    "\n",
    "    # Define Image Data generator for data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        zoom_range = random.uniform(-0.5, 0.5),\n",
    "        horizontal_flip = np.random.randint(0,1),\n",
    "        brightness_range = (0.5, 1.5))\n",
    "    # Define a seed\n",
    "    seed = np.random.randint(1,100)\n",
    "\n",
    "    while success:\n",
    "        #If the video already has the standard FPS, we don't have to do anything \n",
    "        if  fps_in == fps:\n",
    "            # Build frame name\n",
    "            frame_name = 'frame'\n",
    "            for i in range(4-len(str(count))):\n",
    "                frame_name += '0'\n",
    "            frame_name += str(count) + '.jpg'\n",
    "    \n",
    "            # Crop image so mouse is postioned in the center\n",
    "            frame = crop_image(image, expansion)\n",
    "            # Check correct format of frame\n",
    "            if frame.shape != (160,160,3):\n",
    "            #if frame.shape != (160,160):\n",
    "                print('Error frame shape: ', frame.shape)\n",
    "\n",
    "            # Perform random data augmentation\n",
    "            for batch in datagen.flow(frame[None], batch_size=1, seed=seed):\n",
    "                frame = np.array(batch[0], dtype=np.uint8)\n",
    "                break\n",
    "            \n",
    "            # Save frame\n",
    "            cv2.imwrite(os.path.join(dataset_dest_folder, 'features', (csv.split('.')[0] + '_augmented'), frame_name), frame)\n",
    "            \n",
    "            success, image = vidcap.read()\n",
    "            count += 1\n",
    "        # Else we will adjsut the frames we process so we get the standard FPS rate\n",
    "        else:\n",
    "            # We will caluculate the second where we are on the video and scale it to the desired FPS\n",
    "            out_due = int(frames_in / fps_in * fps)\n",
    "    \n",
    "            if out_due > frames_out:\n",
    "                frames_out += 1\n",
    "                # Build frame name\n",
    "                frame_name = 'frame'\n",
    "                for i in range(4-len(str(count))):\n",
    "                    frame_name += '0'\n",
    "                frame_name += str(count) + '.jpg'\n",
    "        \n",
    "                # Crop image so mouse is postioned in the center\n",
    "                frame = crop_image(image, expansion)\n",
    "                # Check correct format of frame\n",
    "                if frame.shape != (160,160,3):\n",
    "                #if frame.shape != (160,160):\n",
    "                    print('Error frame shape: ', frame.shape)\n",
    "                    \n",
    "                # Perform random data augmentation\n",
    "                for batch in datagen.flow(frame[None], batch_size=1, seed=seed):\n",
    "                    frame = np.array(batch[0], dtype=np.uint8)\n",
    "                    break\n",
    "                    \n",
    "                # Save frame\n",
    "                cv2.imwrite(os.path.join(dataset_dest_folder, 'features', (csv.split('.')[0] + '_augmented'), frame_name), frame) \n",
    "                count += 1  \n",
    "            # We will remove those rows that don't correspond to any frame\n",
    "            else:\n",
    "                if count_df < len(df):\n",
    "                    drop_indx.append(count_df)\n",
    "                    \n",
    "            frames_in += 1\n",
    "            count_df += 1\n",
    "            success, image = vidcap.read()\n",
    "            \n",
    "    if  fps_in != fps:\n",
    "        df = df.drop(drop_indx, axis=0)\n",
    "        # Save df as csv\n",
    "        df.to_csv(os.path.join(dataset_dest_folder, 'labels', csv.split('.')[0] + '_augmented.csv'), index=False)\n",
    "        \n",
    "    print(\"Label rows: \", df.shape)\n",
    "    print(\"Video frames: \", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we will create an split file, where all folder will correspond to the taining set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train', 'train']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '../data/processed/ImageDatasetRGB_Augmented/'\n",
    "\n",
    "features = sorted(os.listdir(os.path.join(dataset_path, 'features')))\n",
    "if '.DS_Store' in features:\n",
    "    features.remove('.DS_Store')\n",
    "\n",
    "set_list = []\n",
    "\n",
    "for i in features:\n",
    "    set_list.append('train')\n",
    "\n",
    "print(set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/processed/'\n",
    "dataset_split = pd.DataFrame({\n",
    "    'name': features,\n",
    "    'set': set_list\n",
    "})\n",
    "dataset_split.to_csv(os.path.join(dataset_path, 'augmented_split.csv'), index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "79da1f634b9d48f5768811b03fe06bbb63e4e3154741404ab553ecc445a12d48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
