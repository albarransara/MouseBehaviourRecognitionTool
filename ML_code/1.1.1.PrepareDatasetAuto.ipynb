{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "On this notebook we will:\n",
    "- Split the videos into its frames and crop them using the midbody position\n",
    "- Extract the labels from the DeepLabCutFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read and process the files that contain the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and create the source and destination folders\n",
    "videos_src_folder = '../data/raw/videos'\n",
    "csvs_src_folder = '../data/raw/csvs'\n",
    "dataset_dest_folder = '../data/processed/ImageDatasetRGB'\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(os.path.dirname(dataset_dest_folder)):\n",
    "        os.mkdir(dataset_dest_folder)\n",
    "        os.mkdir(os.path.join(dataset_dest_folder, 'features'))\n",
    "        os.mkdir(os.path.join(dataset_dest_folder, 'labels'))    \n",
    "\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "    print('Dataset Destination Folders already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will delete any unrelated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['1.csv', '2.csv', '3.csv', '4.csv', '5.csv', 'Animal61980.csv',\n",
       "        'Animal62418.csv', 'HD_ChR2_480A.csv', 'HD_ChR2_510A.csv',\n",
       "        'HD_ChR2_586A.csv', 'HD_YFP_037A.csv', 'HD_YFP_443A.csv',\n",
       "        'HD_YFP_463A.csv', 'WT_ChR2_087A.csv', 'WT_ChR2_400A.csv',\n",
       "        'WT_ChR2_425A.csv', 'WT_ChR2_635A.csv', 'WT_ChR2_654A.csv',\n",
       "        'WT_YFP_154A.csv', 'WT_YFP_435A.csv', 'WT_YFP_535A.csv',\n",
       "        'WT_YFP_602A.csv', 'WT_YFP_741A.csv', 'WT_YFP_792.csv'],\n",
       "       dtype='<U18'),\n",
       " array(['037A.mp4', '087A.mp4', '1.mp4', '154A.mp4', '2.mp4', '3.mp4',\n",
       "        '4.mp4', '400A.mp4', '425A.mp4', '435A.mp4', '443A.mp4',\n",
       "        '463A.mp4', '480A.mp4', '5.mp4', '510A.mp4', '535A.mp4',\n",
       "        '586A.mp4', '602A.mp4', '635A.mp4', '654A.mp4', '741A.mp4',\n",
       "        '792.mp4', 'Video_Animal61980_10min.mp4',\n",
       "        'Video_Animal62418_10min.mp4'], dtype='<U29'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the content from the source folders\n",
    "csvs = sorted(os.listdir(csvs_src_folder))\n",
    "videos = sorted(os.listdir(videos_src_folder))\n",
    "\n",
    "# Clean unecessary files\n",
    "count_delated = 0\n",
    "for i in range(len(csvs)):\n",
    "    if csvs[i-count_delated][:2] == '._' :\n",
    "        csvs = np.delete(csvs, i-count_delated)\n",
    "        count_delated += 1\n",
    "    elif 'gitkeep' in csvs[i-count_delated]:\n",
    "        csvs = np.delete(csvs, i-count_delated)\n",
    "        count_delated += 1\n",
    "    elif 'DS_Store' in csvs[i-count_delated]:\n",
    "        csvs = np.delete(csvs, i-count_delated)\n",
    "        count_delated += 1\n",
    "\n",
    "count_delated = 0\n",
    "for i in range(len(videos)):\n",
    "    if  videos[i-count_delated][:2] == '._' :\n",
    "        videos = np.delete(videos, i-count_delated)\n",
    "        count_delated += 1\n",
    "    elif 'gitkeep' in videos[i-count_delated]:\n",
    "        videos = np.delete(videos, i-count_delated)\n",
    "        count_delated += 1\n",
    "    elif 'DS_Store' in videos[i-count_delated]:\n",
    "        videos = np.delete(videos, i-count_delated)\n",
    "        count_delated += 1\n",
    "        \n",
    "csvs, videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will sort them with the same order on both lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.mp4', '2.mp4', '3.mp4', '4.mp4', '5.mp4', 'Video_Animal61980_10min.mp4', 'Video_Animal62418_10min.mp4', '480A.mp4', '510A.mp4', '586A.mp4', '037A.mp4', '443A.mp4', '463A.mp4', '087A.mp4', '400A.mp4', '425A.mp4', '635A.mp4', '654A.mp4', '154A.mp4', '435A.mp4', '535A.mp4', '602A.mp4', '741A.mp4', '792.mp4']\n",
      "['1.csv', '2.csv', '3.csv', '4.csv', '5.csv', 'Animal61980.csv', 'Animal62418.csv', 'HD_ChR2_480A.csv', 'HD_ChR2_510A.csv', 'HD_ChR2_586A.csv', 'HD_YFP_037A.csv', 'HD_YFP_443A.csv', 'HD_YFP_463A.csv', 'WT_ChR2_087A.csv', 'WT_ChR2_400A.csv', 'WT_ChR2_425A.csv', 'WT_ChR2_635A.csv', 'WT_ChR2_654A.csv', 'WT_YFP_154A.csv', 'WT_YFP_435A.csv', 'WT_YFP_535A.csv', 'WT_YFP_602A.csv', 'WT_YFP_741A.csv', 'WT_YFP_792.csv']\n"
     ]
    }
   ],
   "source": [
    "csvs = sorted(csvs)\n",
    "videos_aux = []\n",
    "\n",
    "for file in csvs:\n",
    "    if 'Animal' in file:\n",
    "        name = 'Video_' + file.split('.')[0] + '_10min.mp4'\n",
    "    elif len(file.split('.')[0]) > 2:\n",
    "        name = file.split('.')[0].split('_')[-1] + '.mp4'\n",
    "    else: \n",
    "        name = file.split('.')[0] + '.mp4'\n",
    "    videos_aux.append(videos[np.where(np.char.find(videos, name) == 0)][0])\n",
    "\n",
    "videos = videos_aux\n",
    "print(videos)\n",
    "print(sorted(csvs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a method to automatically find the central position of the mouse and crop the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, expansion):\n",
    "    \n",
    "    # Start by converting the image to Gray scale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Rescale the values to highlight constrasted areas\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Crop the box\n",
    "    thresh2 = np.invert(thresh)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    close = cv2.morphologyEx(thresh2, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    \n",
    "    # We want to avoid noise, for that we will just consider the biggest countour since it is going to be the box\n",
    "    c = 0\n",
    "    c_len = len(cnts[0])\n",
    "    for i in range(len(cnts[1:])):\n",
    "        if len(cnts[i]) > c_len:\n",
    "            c = i\n",
    "            c_len = len(cnts[i])          \n",
    "    \n",
    "    # Obtain bounding rectangle to get the box coordinates\n",
    "    x,y,w,h = cv2.boundingRect(cnts[c])\n",
    "\n",
    "    # If the box is way to big, we won't need to crop it, else we will \n",
    "    # If the box isnot detected by the filter, then we can consider it is big enough to not crop it\n",
    "    if not (x+w - x) < image.shape[0]//4:\n",
    "        image = image[y:y+h, x:x+w]\n",
    "        thresh = thresh[y:y+h, x:x+w]\n",
    "\n",
    "    # We can now look for the mouse contour\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "   \n",
    "    # We want to avoid noise, for that we will just consider the biggest countour since it is going to be the mouse, as long as it is not\n",
    "    # to close to the extremes of the image, since that would mean it is an external object\n",
    "    c = 0\n",
    "    c_len = len(cnts[0])\n",
    "    for i in range(len(cnts[1:])):\n",
    "        if len(cnts[i]) > c_len:\n",
    "            # Obtain bounding rectangle to get measurements\n",
    "            x,y,w,h = cv2.boundingRect(cnts[i])\n",
    "            if not (y < 100) or not (y+h > image.shape[0]-100):\n",
    "                c = i\n",
    "                c_len = len(cnts[i])\n",
    "\n",
    "    # Crate a bounding box arround the mouse\n",
    "    x,y,w,h = cv2.boundingRect(cnts[c])\n",
    "    \n",
    "    # Find centroid, this will be the center position of the mouse\n",
    "    M = cv2.moments(cnts[c])            \n",
    "    cX = int(M[\"m10\"] / (M[\"m00\"] + 1e-10))\n",
    "    cY = int(M[\"m01\"] / (M[\"m00\"]+ 1e-10))\n",
    "    midbody = [cX,cY]\n",
    "    \n",
    "    top = max(0, midbody[0] - expansion) - max(0, midbody[0] + expansion - image.shape[1])\n",
    "    bottom = min(image.shape[1], midbody[0] + expansion) + max(0, expansion - midbody[0])\n",
    "    left = max(0, midbody[1] - expansion) - max(0, midbody[1] + expansion - image.shape[0])\n",
    "    right = min(image.shape[0], midbody[1] + expansion) + max(0, expansion - midbody[1])\n",
    "   \n",
    "    return image[left:right,top:bottom]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can start processing the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video:  1.mp4\n",
      "CSV:  1.csv\n",
      "1.csv\n",
      "DF:  (10884, 2)\n",
      "Video FPS:  29.97002753079876\n",
      "Label rows:  (3631, 2)\n",
      "Video frames:  3631\n",
      "Video:  2.mp4\n",
      "CSV:  2.csv\n",
      "2.csv\n",
      "DF:  (12055, 2)\n",
      "Video FPS:  29.97002982834519\n",
      "Label rows:  (4022, 2)\n",
      "Video frames:  4022\n",
      "Video:  3.mp4\n",
      "CSV:  3.csv\n",
      "3.csv\n",
      "DF:  (12795, 2)\n",
      "Video FPS:  29.9700281034881\n",
      "Label rows:  (4268, 2)\n",
      "Video frames:  4269\n",
      "Video:  4.mp4\n",
      "CSV:  4.csv\n",
      "4.csv\n",
      "DF:  (13558, 2)\n",
      "Video FPS:  29.97002873232843\n",
      "Label rows:  (4523, 2)\n",
      "Video frames:  4524\n",
      "Video:  5.mp4\n",
      "CSV:  5.csv\n",
      "5.csv\n",
      "DF:  (12178, 2)\n",
      "Video FPS:  29.970029527122687\n",
      "Label rows:  (4063, 2)\n",
      "Video frames:  4063\n",
      "Video:  Video_Animal61980_10min.mp4\n",
      "CSV:  Animal61980.csv\n",
      "Animal61980.csv\n",
      "DF:  (6000, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6000, 2)\n",
      "Video frames:  6000\n",
      "Video:  Video_Animal62418_10min.mp4\n",
      "CSV:  Animal62418.csv\n",
      "Animal62418.csv\n",
      "DF:  (6000, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6000, 2)\n",
      "Video frames:  6000\n",
      "Video:  480A.mp4\n",
      "CSV:  HD_ChR2_480A.csv\n",
      "HD_ChR2_480A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  510A.mp4\n",
      "CSV:  HD_ChR2_510A.csv\n",
      "HD_ChR2_510A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  586A.mp4\n",
      "CSV:  HD_ChR2_586A.csv\n",
      "HD_ChR2_586A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  037A.mp4\n",
      "CSV:  HD_YFP_037A.csv\n",
      "HD_YFP_037A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  443A.mp4\n",
      "CSV:  HD_YFP_443A.csv\n",
      "HD_YFP_443A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  463A.mp4\n",
      "CSV:  HD_YFP_463A.csv\n",
      "HD_YFP_463A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  087A.mp4\n",
      "CSV:  WT_ChR2_087A.csv\n",
      "WT_ChR2_087A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  400A.mp4\n",
      "CSV:  WT_ChR2_400A.csv\n",
      "WT_ChR2_400A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  425A.mp4\n",
      "CSV:  WT_ChR2_425A.csv\n",
      "WT_ChR2_425A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  635A.mp4\n",
      "CSV:  WT_ChR2_635A.csv\n",
      "WT_ChR2_635A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  654A.mp4\n",
      "CSV:  WT_ChR2_654A.csv\n",
      "WT_ChR2_654A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  154A.mp4\n",
      "CSV:  WT_YFP_154A.csv\n",
      "WT_YFP_154A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  435A.mp4\n",
      "CSV:  WT_YFP_435A.csv\n",
      "WT_YFP_435A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  535A.mp4\n",
      "CSV:  WT_YFP_535A.csv\n",
      "WT_YFP_535A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  602A.mp4\n",
      "CSV:  WT_YFP_602A.csv\n",
      "WT_YFP_602A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  741A.mp4\n",
      "CSV:  WT_YFP_741A.csv\n",
      "WT_YFP_741A.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n",
      "Video:  792.mp4\n",
      "CSV:  WT_YFP_792.csv\n",
      "WT_YFP_792.csv\n",
      "DF:  (6600, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6600, 2)\n",
      "Video frames:  6600\n"
     ]
    }
   ],
   "source": [
    "expansion = 80\n",
    "behaviours = ['grooming', 'rearing']\n",
    "fps = 10\n",
    "\n",
    "for csv, video in zip(csvs[:], videos[:]):\n",
    "\n",
    "    print('Video: ', video)\n",
    "    print('CSV: ', csv)\n",
    "    \n",
    "    # Read columns from csvs corresponding to the behaviours\n",
    "    df = pd.read_csv(os.path.join(csvs_src_folder, csv), header=0)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    \n",
    "    if 'rearing' in df.columns:\n",
    "        df = df[behaviours]\n",
    "    else:\n",
    "        rearing = np.maximum(df['rearing mig'], df['rearing paret'])\n",
    "        df_aux = pd.DataFrame()\n",
    "        df_aux['grooming'] = df['grooming']\n",
    "        df_aux['rearing'] = rearing \n",
    "        df = df_aux\n",
    "        \n",
    "    # Change voids per 0 \n",
    "    df.fillna(0, inplace=True)\n",
    "    # Change data format\n",
    "    df = df.astype(int)\n",
    "    # Reset row indexes\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    # Save df as csv\n",
    "    df.to_csv(os.path.join(dataset_dest_folder, 'labels', csv.split('.')[0] + '.csv'), index=False)\n",
    "    print(csv)\n",
    "    print('DF: ', df.shape)\n",
    "\n",
    "    # Get video frames\n",
    "    os.mkdir(os.path.join(dataset_dest_folder, 'features', csv.split('.')[0]))\n",
    "    vidcap = cv2.VideoCapture(os.path.join(videos_src_folder, video))              \n",
    "\n",
    "    # Get the video FPS rate\n",
    "    fps_in = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    print('Video FPS: ', fps_in)\n",
    "\n",
    "    # Start processing each frame\n",
    "    success,image = vidcap.read()\n",
    "\n",
    "    frames_in = 0\n",
    "    frames_out = 0\n",
    "    count = 0\n",
    "    count_df = 0\n",
    "    drop_indx = []\n",
    "    \n",
    "    while success:\n",
    "        #If the video already has the standard FPS, we don't have to do anything \n",
    "        if  fps_in == fps:\n",
    "            # Build frame name\n",
    "            frame_name = 'frame'\n",
    "            for i in range(4-len(str(count))):\n",
    "                frame_name += '0'\n",
    "            frame_name += str(count) + '.jpg'\n",
    "    \n",
    "            # Crop image so mouse is postioned in the center\n",
    "            frame = crop_image(image, expansion)\n",
    "             # Check that size is correct and uniform\n",
    "            if frame.shape != (160, 160, 3):\n",
    "                print(frame.shape == (160, 160, 3))\n",
    "                print(frame.shape)\n",
    "\n",
    "            # Normalize the RGB values to be between 0 and 1\n",
    "            frame = frame / 255.0\n",
    "            if frame.max() > 1:\n",
    "                print(frame.max())\n",
    "                    \n",
    "            # Save frame\n",
    "            cv2.imwrite(os.path.join(dataset_dest_folder, 'features', csv.split('.')[0], frame_name), frame)\n",
    "            \n",
    "            success, image = vidcap.read()\n",
    "            count += 1\n",
    "        # Else we will adjsut the frames we process so we get the standard FPS rate\n",
    "        else:\n",
    "            # We will caluculate the second where we are on the video and scale it to the desired FPS\n",
    "            out_due = int(frames_in / fps_in * fps)\n",
    "    \n",
    "            if out_due > frames_out:\n",
    "                frames_out += 1\n",
    "                # Build frame name\n",
    "                frame_name = 'frame'\n",
    "                for i in range(4-len(str(count))):\n",
    "                    frame_name += '0'\n",
    "                frame_name += str(count) + '.jpg'\n",
    "        \n",
    "                # Crop image so mouse is postioned in the center\n",
    "                frame = crop_image(image, expansion)\n",
    "                # Check that size is correct and uniform\n",
    "                if frame.shape != (160, 160, 3):\n",
    "                    print(frame.shape == (160, 160, 3))\n",
    "                    print(frame.shape)\n",
    "\n",
    "                # Normalize the RGB values to be between 0 and 1\n",
    "                frame = frame / 255.0\n",
    "                if frame.max() > 1:\n",
    "                    print(frame.max())\n",
    "                    \n",
    "                # Save frame\n",
    "                cv2.imwrite(os.path.join(dataset_dest_folder, 'features', csv.split('.')[0], frame_name), frame) \n",
    "                count += 1  \n",
    "            # We will remove those rows that don't correspond to any frame\n",
    "            else:\n",
    "                if count_df < len(df):\n",
    "                    drop_indx.append(count_df)\n",
    "                    \n",
    "            frames_in += 1\n",
    "            count_df += 1\n",
    "            success, image = vidcap.read()\n",
    "            \n",
    "    if  fps_in != fps:\n",
    "        df = df.drop(drop_indx, axis=0)\n",
    "        # Save df as csv\n",
    "        df.to_csv(os.path.join(dataset_dest_folder, 'labels', csv.split('.')[0] + '.csv'), index=False)\n",
    "        \n",
    "    print(\"Label rows: \", df.shape)\n",
    "    print(\"Video frames: \", count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "79da1f634b9d48f5768811b03fe06bbb63e4e3154741404ab553ecc445a12d48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
